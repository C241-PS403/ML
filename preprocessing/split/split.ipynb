{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_dir, output_train, output_test, output_val, train_split=0.7, test_split=0.2, val_split=0.1):\n",
    "    \n",
    "    create_dir(output_train)\n",
    "    create_dir(output_test)\n",
    "    create_dir(output_val)\n",
    "\n",
    "    class_dirs = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]\n",
    "    \n",
    "    for class_dir in class_dirs:\n",
    "\n",
    "        class_path = os.path.join(input_dir, class_dir)\n",
    "        \n",
    "        image_paths = glob(os.path.join(class_path, '*.*'))\n",
    "        \n",
    "        random.shuffle(image_paths)\n",
    "        \n",
    "        total_images = len(image_paths)\n",
    "        train_idx = int(total_images * train_split)\n",
    "        test_idx = int(total_images * (train_split + test_split))\n",
    "        \n",
    "        train_images = image_paths[:train_idx]\n",
    "        test_images = image_paths[train_idx:test_idx]\n",
    "        val_images = image_paths[test_idx:]\n",
    "\n",
    "        def copy_files(files, target_dir, class_name):\n",
    "            for file in files:\n",
    "                dest_dir = os.path.join(target_dir, class_name)\n",
    "                create_dir(dest_dir)\n",
    "                shutil.copy(file, dest_dir)\n",
    "    \n",
    "        copy_files(train_images, output_train, class_dir)\n",
    "        copy_files(test_images, output_test, class_dir)\n",
    "        copy_files(val_images, output_val, class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'C:\\\\Bangkit\\\\ML\\\\code\\\\preprocessing\\\\augmentation\\\\new-dataset-augmentation'\n",
    "output_train_directory = 'C:\\\\Bangkit\\\\ML\\\\code\\\\preprocessing\\\\split\\\\new-dataset-split\\\\train'\n",
    "output_test_directory = 'C:\\\\Bangkit\\\\ML\\\\code\\\\preprocessing\\\\split\\\\new-dataset-split\\\\test'\n",
    "output_val_directory = 'C:\\\\Bangkit\\\\ML\\\\code\\\\preprocessing\\\\split\\\\new-dataset-split\\\\val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(input_directory, output_train_directory, output_test_directory, output_val_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
